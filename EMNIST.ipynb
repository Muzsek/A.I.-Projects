{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPd67Z3r3BtzZe4ZKWlD07D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muzsek/A.I.-Projects/blob/main/EMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgnKeyeiwsr6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                          transforms.Grayscale(),\n",
        "                          transforms.RandomRotation(degrees = 15),\n",
        "                          transforms.Resize((28,28)),\n",
        "                          transforms.RandomHorizontalFlip(p=0.5),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.1738,),(0.3249,)),\n",
        "                          ])"
      ],
      "metadata": {
        "id": "qPoL7cBhxdHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.EMNIST(root = \"./data\", split = \"byclass\",train = True, download = True, transform = transform)\n",
        "test_dataset = torchvision.datasets.EMNIST(root = \"./data\", split = \"byclass\", train = False, download = True, transform = transform)\n",
        "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
        "print(f\"Test dataset: {len(test_dataset)} samples\")"
      ],
      "metadata": {
        "id": "9rM1pi6YxB_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea71726-7489-478b-a417-425955134247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset: 697932 samples\n",
            "Test dataset: 116323 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from torch.utils.data import subset\n",
        "subset_size = 200000\n",
        "\n",
        "indices = list(range(len(train_dataset)))\n",
        "subset_indices = indices[:subset_size]\n",
        "sub_train_dataset = torch.utils.data.Subset(train_dataset, subset_indices)\n",
        "print(f\"Subseted Train dataset: {len(sub_train_dataset)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtxFIOxKJOx0",
        "outputId": "9d91805b-e57d-4b41-b323-03da9a7d2867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subseted Train dataset: 200000 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(sub_train_dataset, batch_size =64, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 64, shuffle = False)"
      ],
      "metadata": {
        "id": "BCmHkiVfxpAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = 0.0\n",
        "std = 0.0\n",
        "total_images = 0\n",
        "\n",
        "for images, _ in train_dataloader:\n",
        "    batch_samples = images.size(0)  # batch m√©rete\n",
        "    images = images.view(batch_samples, -1)  # flatten: (batch, pixels)\n",
        "    mean += images.mean(1).sum()\n",
        "    std += images.std(1).sum()\n",
        "    total_images += batch_samples\n",
        "\n",
        "mean /= total_images\n",
        "std /= total_images\n",
        "\n",
        "print(f\"EMNIST mean: {mean.item():.4f}\")\n",
        "print(f\"EMNIST std: {std.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQBDV_-3eCnq",
        "outputId": "7897e585-cb52-4376-aecf-796fd92da966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EMNIST mean: 0.1738\n",
            "EMNIST std: 0.3249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emnist_byclass_labels = {\n",
        "    **{i: str(i) for i in range(10)},\n",
        "    **{i + 10: chr(ord('A') + i) for i in range(26)},\n",
        "    **{i + 36: chr(ord('a') + i) for i in range(26)}\n",
        "}\n",
        "#torch.manual_seed(42)\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Train features' shape: {train_features.shape}\")\n",
        "print(f\"Train labels' shape: {train_labels.shape}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {emnist_byclass_labels[int(label)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "uCg6MMfuyIVT",
        "outputId": "e6fe195d-e3ca-43ad-e1ae-1c5dc2b407a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features' shape: torch.Size([64, 1, 28, 28])\n",
            "Train labels' shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"All classes in EMNIST: {len(train_dataset.classes)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAhfZD3lyYSF",
        "outputId": "349efc8d-18f4-4fb0-8b12-09ee79384557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All classes in EMNIST: 62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1_block = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "        self.conv2_block = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 62)  # EMNIST byclass = 62 oszt√°ly\n",
        "        )\n",
        "    def forward(self, x):\n",
        "      # x = self.conv1_block(x)\n",
        "      # print(x.shape)\n",
        "      # x = self.conv2_block(x)\n",
        "      # print(x.shape)\n",
        "      # x = torch.flatten(x, 1)\n",
        "      # print(\"After flatten:\", x.shape)\n",
        "      # x = self.classifier(x)\n",
        "      # return x\n",
        "      return self.classifier(self.conv2_block(self.conv1_block(x)))\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Current device: {device}\")\n",
        "model_0 = CNN().to(device)\n",
        "next(model_0.parameters()).is_cuda"
      ],
      "metadata": {
        "id": "qSgcVXyR1Q1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c526b545-f55b-4c01-ac40-c8a2279069c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model_0.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "-R73cnvPGpez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Truth labels for predictions.\n",
        "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
        "\n",
        "    Returns:\n",
        "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
        "    \"\"\"\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "3Yqlu1mAHD7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 3\n",
        "for epoch in range(epoch):\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "    train_loss = 0\n",
        "    test_loss = 0\n",
        "    model_0.train()\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_pred = model_0(X)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch % 400 == 0:\n",
        "          print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "          print(f\"Loss: {loss.item()}\")\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            # 1. Forward pass\n",
        "            test_pred = model_0(X)\n",
        "\n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "        test_loss /= len(test_dataloader)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(test_dataloader)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n Accuracy:{test_acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg3-xrSxGwDC",
        "outputId": "80a6af18-3b82-4920-b24e-961614dc075a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0/200000 samples\n",
            "Loss: 4.157873630523682\n",
            "Looked at 25600/200000 samples\n",
            "Loss: 1.3981599807739258\n",
            "Looked at 51200/200000 samples\n",
            "Loss: 0.6270049214363098\n",
            "Looked at 76800/200000 samples\n",
            "Loss: 0.5878857970237732\n",
            "Looked at 102400/200000 samples\n",
            "Loss: 0.4247507154941559\n",
            "Looked at 128000/200000 samples\n",
            "Loss: 0.586607038974762\n",
            "Looked at 153600/200000 samples\n",
            "Loss: 0.5423743724822998\n",
            "Looked at 179200/200000 samples\n",
            "Loss: 0.5113822817802429\n",
            "\n",
            "Train loss: 0.00000 | Test loss: 0.52592, Test acc: 82.21%\n",
            " Accuracy:82.21\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0/200000 samples\n",
            "Loss: 0.6645208597183228\n",
            "Looked at 25600/200000 samples\n",
            "Loss: 0.48878178000450134\n",
            "Looked at 51200/200000 samples\n",
            "Loss: 0.34480899572372437\n",
            "Looked at 76800/200000 samples\n",
            "Loss: 0.5855316519737244\n",
            "Looked at 102400/200000 samples\n",
            "Loss: 0.5244772434234619\n",
            "Looked at 128000/200000 samples\n",
            "Loss: 0.4147442877292633\n",
            "Looked at 153600/200000 samples\n",
            "Loss: 0.5204923152923584\n",
            "Looked at 179200/200000 samples\n",
            "Loss: 0.7927495837211609\n",
            "\n",
            "Train loss: 0.00000 | Test loss: 0.45306, Test acc: 84.57%\n",
            " Accuracy:84.57\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0/200000 samples\n",
            "Loss: 0.7392803430557251\n",
            "Looked at 25600/200000 samples\n",
            "Loss: 0.662841796875\n",
            "Looked at 51200/200000 samples\n",
            "Loss: 0.2944035530090332\n",
            "Looked at 76800/200000 samples\n",
            "Loss: 0.4765606224536896\n",
            "Looked at 102400/200000 samples\n",
            "Loss: 0.40891972184181213\n",
            "Looked at 128000/200000 samples\n",
            "Loss: 0.6969037055969238\n",
            "Looked at 153600/200000 samples\n",
            "Loss: 0.6781665682792664\n",
            "Looked at 179200/200000 samples\n",
            "Loss: 0.40412190556526184\n",
            "\n",
            "Train loss: 0.00000 | Test loss: 0.43825, Test acc: 84.64%\n",
            " Accuracy:84.64\n"
          ]
        }
      ]
    }
  ]
}